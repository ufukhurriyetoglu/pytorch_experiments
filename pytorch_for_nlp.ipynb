{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c603f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38384a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba03919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c92b27c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9794e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8c4f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb3f96da3d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffc56a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f1eead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25cd3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize=\"spacy\", tokenizer_language=\"en_core_web_sm\",lower=True)\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "333fb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = datasets.TREC.splits(TEXT, LABEL)\n",
    "train, val = train.split(random_state=random.seed(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac2dd779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['how', 'do', 'you', 'say', '2', 'in', 'latin', '?'], 'label': 'ENTY'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00348e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35d3461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41bb5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train, val, test), \n",
    "    batch_size = 64,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce5357ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "474bb5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self, vocabulary_size, embedding_size, kernels_number, kernel_sizes,\n",
    "        output_size, dropout_rate):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocabulary_size, embedding_size)\n",
    "        self.convolution_layers = nn.ModuleList(\n",
    "            nn.ModuleList(\n",
    "                [\n",
    "                    nn.Conv2d(\n",
    "                    in_channels=1, \n",
    "                    out_channels=kernels_number, \n",
    "                    kernel_size=(k, embedding_size))\n",
    "                for k in kernel_sizes\n",
    "            ]))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fully_connected = nn.Linear(\n",
    "            len(kernel_sizes) * kernels_number, output_size)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        \n",
    "        text = text.permut(1,0)\n",
    "        input_embeddings = self.embedding(text)\n",
    "        input_embeddings = input_embeddings.unsqueeze(1)\n",
    "        conved = [\n",
    "            F.relu(convolution_layer(input_embeddings)).squeeze(3)\n",
    "            for convolution_layer in self.convolution_layers\n",
    "        ]\n",
    "        \n",
    "        pooled = [\n",
    "            F.max_pool1d(conv, conv.shape[2]).squeeze(3) for conv in conved\n",
    "        ]\n",
    "        \n",
    "        concat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        \n",
    "        final_output = self.fully_connected(concat)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e101b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 2679\n",
    "embedding_size = 100\n",
    "kernels_number = 100\n",
    "kernel_sizes = [2, 3, 4]\n",
    "output_size = 6\n",
    "dropout_rate = 0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08cd6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(\n",
    "    vocabulary_size, embedding_size, kernels_number, kernel_sizes, \n",
    "    output_size, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3295d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embedding): Embedding(2679, 100)\n",
      "  (convolution_layers): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fully_connected): Linear(in_features=300, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54eec102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(2679, 100)\n",
       "  (convolution_layers): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(2, 100), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(3, 100), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(4, 100), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fully_connected): Linear(in_features=300, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ed07f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af52077",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8d9deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e84ace05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, actual_label):\n",
    "    max_predictions = predictions.argmax(dim=1, keepdim = True, )\n",
    "    correct_predictions = max_predictions.squeeze().eq(actual_label)\n",
    "    accuracy = correct_predictions.sum() / torch.cuda.FloatTensor([actual_label.shape[0]])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b79ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0 \n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predictions = model(batch.text)\n",
    "\n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            acc = categorical_accuracy(predictions, batch.label)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34824bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_environment",
   "language": "python",
   "name": "pytorch_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
